# Architecture Plan: Separated Scraping and Storage Services

## Overview

This document outlines the architecture plan for separating the scraping process from the storage process in MoneyMan to enhance security by isolating sensitive bank credentials from external service access.

## Current Architecture

```mermaid
graph TB
    subgraph "MoneyMan (Single Process)"
        A[Bank Credentials]
        B[Scraping Logic]
        C[Storage Services]
        D[External API Keys]
        E[Telegram Notifications]
        F[All Dependencies Mixed]
    end
```

**Security Issues:**
- Single process has access to both bank credentials AND external service API keys
- Large attack surface - compromise of any component exposes everything
- No isolation between sensitive operations

## Proposed Separated Architecture

```mermaid
graph TB
    subgraph "Single Docker Container"
        subgraph "Scraper Process (UID: 1001)"
            S[Scraper Service]
            SC[Bank Credentials]
            SM[node_modules:<br/>â€¢ israeli-bank-scrapers<br/>â€¢ puppeteer<br/>â€¢ zeromq]
        end
        
        subgraph "Storage Process (UID: 1002)"  
            T[Storage Service]
            TC[API Keys]
            TM[node_modules:<br/>â€¢ googleapis<br/>â€¢ ynab<br/>â€¢ @azure/*<br/>â€¢ telegram-api<br/>â€¢ zeromq]
        end
        
        subgraph "Orchestrator Process (UID: 1003)"
            O[Orchestrator Service]
            OC[Logging & Coordination]
            OM[node_modules:<br/>â€¢ zeromq<br/>â€¢ winston<br/>â€¢ minimal deps]
        end
        
        S -->|IPC ZeroMQ| O
        O -->|IPC ZeroMQ| T
    end
    
    S --> BS[Bank Sites]
    T --> EA[External APIs:<br/>Google Sheets<br/>YNAB<br/>Azure<br/>Telegram]
```

## Components

### 1. Scraper Service
**Purpose:** Minimal service that only handles bank scraping
**Location:** `scraper-service/index.ts`
**Responsibilities:**
- Execute bank account scraping using existing scraper logic
- Send results via ZeroMQ to orchestrator service
- Handle scraping errors and send error messages
- Send status updates during scraping process
- Send metadata and failure screenshots

**Dependencies:**
- **Completely separate node_modules**: Only scraping-related packages installed
  - `israeli-bank-scrapers` and its dependencies
  - `zeromq` for communication
  - Minimal Node.js runtime dependencies
  - **NO** external service API libraries (Google APIs, YNAB SDK, Azure SDK, etc.)
- ZeroMQ for communication
- Bank scraping libraries

**Security:**
- Runs as `scraper` user (UID 1001)
- Only has access to bank credentials and scraping configuration
- No access to external service API keys
- **Dependency isolation**: Cannot access external service libraries even if compromised
- **Environment variable isolation**: Only receives scraping-related environment variables
- Can be network-restricted to only bank domains

### 2. Storage Service
**Purpose:** Handles all external storage operations
**Location:** `storage-service/index.ts`
**Responsibilities:**
- Receive processed results from orchestrator service via ZeroMQ
- Save results to configured storage services (Google Sheets, YNAB, etc.)
- Handle error notifications
- Process metadata and screenshots

**Dependencies:**
- **Completely separate node_modules**: Only external service API libraries
  - Google APIs SDK for Sheets integration
  - YNAB SDK for budget integration
  - Azure SDK for blob storage
  - `zeromq` for communication
  - **NO** bank scraping libraries or related dependencies
- ZeroMQ for communication
- External service API libraries

**Security:**
- Runs as `storage` user (UID 1002)
- Only has access to external service API keys and storage configuration
- No access to bank credentials
- **Dependency isolation**: Cannot access bank scraping libraries even if compromised
- **Environment variable isolation**: Only receives external service API credentials
- Can be network-restricted from bank domains

### 3. Orchestrator Service
**Purpose:** Coordinates communication and handles notifications
**Location:** `orchestrator-service/index.ts`
**Responsibilities:**
- Coordinate scraping workflow
- Handle Telegram notifications and logging
- Route messages between scraper and storage services
- Manage error handling and recovery
- Process control and lifecycle management

**Dependencies:**
- **Minimal separate node_modules**: Only coordination libraries
  - `zeromq` for communication
  - `winston` or similar for logging
  - Telegram Bot API libraries
  - **NO** bank scraping or external storage libraries

**Security:**
- Runs as `orchestrator` user (UID 1003)
- Has access to notification credentials and coordination configuration only
- No access to bank credentials or storage API keys
- **Dependency isolation**: Cannot access scraping or storage libraries
- **Environment variable isolation**: Only receives notification and logging credentials

### 4. Communication Layer
**Protocol:** ZeroMQ with IPC transport (Unix domain sockets)
**Endpoints:** 
- `ipc:///tmp/scraper-orchestrator.sock` 
- `ipc:///tmp/orchestrator-storage.sock`
**Message Format:** JSON with typed interfaces

```typescript
interface ScraperMessage {
  type: 'results' | 'error' | 'status' | 'metadata' | 'screenshots' | 'finished';
  data: any;
}

interface OrchestratorMessage {
  type: 'store_results' | 'notify' | 'log' | 'error';
  data: any;
}
```

**Message Types:**
- `results`: Account scraping results
- `error`: Error messages with stack traces
- `status`: Status updates during scraping
- `metadata`: Run metadata
- `screenshots`: Failure screenshots
- `finished`: Indicates scraping completion
- `store_results`: Processed data ready for storage
- `notify`: Notification requests
- `log`: Logging messages

## Implementation Strategy

### Phase 1: Core Infrastructure
1. Create `scraper-service/` directory with minimal scraper process
2. Create `storage-service/` directory with storage and notification logic
3. Implement ZeroMQ communication layer
4. Define typed message interfaces

### Phase 2: Service Separation
1. Extract scraping logic from main process to scraper service
2. Extract storage logic from main process to storage service
3. Implement message passing for all communication
4. Ensure graceful error handling across services

### Phase 3: Security Hardening
1. Create separate Docker users for each service
2. Implement separate Dockerfile for separated mode
3. Add network restrictions capability (iptables rules)
4. Document security configuration options

### Phase 4: Backward Compatibility
1. Maintain unified mode as default
2. Add `SEPARATED_MODE` environment variable
3. Ensure all existing functionality works in both modes
4. Add comprehensive testing for both modes

## Dependencies and Package Separation

### Key Security Feature: Isolated node_modules

The separated architecture implements **complete dependency isolation** between services, ensuring that:

- **Scraper Service** only has access to scraping-related packages
- **Storage Service** only has access to external API packages
- **Orchestrator Service** only has access to coordination and notification packages
- **No cross-service dependency access** even if one service is compromised
- **Shared Types Only**: Services only share TypeScript type definitions, no runtime code

### Scraper Service Dependencies (`scraper-service/package.json`)

```json
{
  "name": "moneyman-scraper",
  "dependencies": {
    "israeli-bank-scrapers": "^1.x.x",
    "zeromq": "^6.x.x",
    "puppeteer": "^21.x.x"
  }
}
```

**Explicitly excludes:**
- `@google-cloud/storage`
- `googleapis` 
- `ynab`
- `@azure/storage-blob`
- `node-telegram-bot-api`
- Any external service SDK

### Storage Service Dependencies (`storage-service/package.json`)

```json
{
  "name": "moneyman-storage", 
  "dependencies": {
    "googleapis": "^128.x.x",
    "ynab": "^1.x.x", 
    "@azure/storage-blob": "^12.x.x",
    "zeromq": "^6.x.x"
  }
}
```

**Explicitly excludes:**
- `israeli-bank-scrapers`
- `puppeteer` 
- `node-telegram-bot-api` (moved to orchestrator)
- Any bank scraping related libraries

### Orchestrator Service Dependencies (`orchestrator-service/package.json`)

```json
{
  "name": "moneyman-orchestrator",
  "dependencies": {
    "zeromq": "^6.x.x",
    "winston": "^3.x.x",
    "node-telegram-bot-api": "^0.x.x"
  }
}
```

**Explicitly excludes:**
- `israeli-bank-scrapers`
- External storage service libraries
- `puppeteer`

### Shared Types Package (`shared-types/package.json`)

```json
{
  "name": "moneyman-shared-types",
  "dependencies": {},
  "devDependencies": {
    "typescript": "^5.x.x"
  }
}
```

**Contains only:**
- TypeScript interface definitions
- No runtime dependencies
- No implementation code

### Implementation Strategy

1. **Separate package.json files**: Each service has its own dependency manifest
2. **Multi-stage Docker builds**: Each service container only contains its required dependencies
3. **Build-time separation**: Dependencies installed independently for each service
4. **Runtime isolation**: Services cannot access each other's node_modules

### Docker Implementation

```dockerfile
# Dockerfile.separated - Single Container with Multiple Processes
FROM ghcr.io/puppeteer/puppeteer:21.0.0 AS base

# Create users with specific UIDs  
USER root
RUN groupadd -g 1001 scraper && useradd -u 1001 -g scraper -s /bin/bash scraper
RUN groupadd -g 1002 storage && useradd -u 1002 -g storage -s /bin/bash storage
RUN groupadd -g 1003 orchestrator && useradd -u 1003 -g orchestrator -s /bin/bash orchestrator

# Create separate directories for each service with proper ownership
WORKDIR /app
RUN mkdir -p scraper-service storage-service orchestrator-service shared-types

# Install dependencies for each service separately
COPY scraper-service/package*.json ./scraper-service/
COPY storage-service/package*.json ./storage-service/
COPY orchestrator-service/package*.json ./orchestrator-service/
COPY shared-types/package*.json ./shared-types/

# Install scraper dependencies as scraper user
USER scraper
WORKDIR /app/scraper-service
RUN npm ci --production

# Install storage dependencies as storage user  
USER storage
WORKDIR /app/storage-service
RUN npm ci --production

# Install orchestrator dependencies as orchestrator user
USER orchestrator
WORKDIR /app/orchestrator-service
RUN npm ci --production

# Install shared types
USER root
WORKDIR /app/shared-types
RUN npm ci --production

# Copy source code with proper ownership
WORKDIR /app
COPY --chown=scraper:scraper scraper-service/ ./scraper-service/
COPY --chown=storage:storage storage-service/ ./storage-service/
COPY --chown=orchestrator:orchestrator orchestrator-service/ ./orchestrator-service/
COPY --chown=root:root shared-types/ ./shared-types/

# Create IPC socket directory
RUN mkdir -p /tmp/moneyman-ipc
RUN chmod 777 /tmp/moneyman-ipc

# Entry point script to start all processes with environment filtering
COPY docker-entrypoint-separated.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

ENTRYPOINT ["/entrypoint.sh"]
```

## File Structure

```
moneyman/
â”œâ”€â”€ src/                           # Existing unified code  
â”‚   â”œâ”€â”€ scraper/                   # Scraping logic (types only shared)
â”‚   â”œâ”€â”€ bot/storage/               # Storage logic (types only shared)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scraper-service/
â”‚   â”œâ”€â”€ index.ts                   # Minimal scraper process
â”‚   â”œâ”€â”€ package.json               # Only scraper dependencies
â”‚   â””â”€â”€ node_modules/              # Isolated scraper dependencies
â”œâ”€â”€ storage-service/
â”‚   â”œâ”€â”€ index.ts                   # Storage process
â”‚   â”œâ”€â”€ package.json               # Only storage dependencies  
â”‚   â””â”€â”€ node_modules/              # Isolated storage dependencies
â”œâ”€â”€ orchestrator-service/
â”‚   â”œâ”€â”€ index.ts                   # Orchestrator process
â”‚   â”œâ”€â”€ package.json               # Only orchestration dependencies
â”‚   â””â”€â”€ node_modules/              # Isolated orchestrator dependencies
â”œâ”€â”€ shared-types/
â”‚   â”œâ”€â”€ index.ts                   # Shared TypeScript interfaces only
â”‚   â””â”€â”€ package.json               # Types only (no runtime dependencies)
â”œâ”€â”€ Dockerfile.separated           # Single container with separated processes
â”œâ”€â”€ docker-entrypoint-separated.sh # Entry point for separated container
â””â”€â”€ package.json                   # Root package (dev dependencies only)
```

## Configuration

### Environment Variables
- `SEPARATED_MODE`: Enable separated mode (default: false)

**Environment Variable Security:**
Each service receives only the environment variables it needs through runtime filtering:
- **Scraper Service**: Only bank credentials and scraping configuration
- **Storage Service**: Only external service API credentials and storage configuration  
- **Orchestrator Service**: Only notification credentials and coordination settings

**Note:** IPC transport eliminates the need for configurable endpoints as Unix domain sockets provide secure, fast inter-process communication within the same container.

### Usage Modes

#### Unified Mode (Default - Backward Compatible)
```bash
npm start
# or
docker run moneyman
```

#### Separated Mode (Enhanced Security) with MONEYMAN_CONFIG

**1. Create Configuration JSON:**
```bash
# Create config.json with your complete configuration
cat > config.json << 'EOF'
{
  "accounts": [
    {
      "companyId": "hapoalim",
      "userCode": "AB1234",
      "password": "your-password"
    }
  ],
  "storage": {
    "googleSheets": {
      "serviceAccountPrivateKey": "-----BEGIN PRIVATE KEY-----...",
      "serviceAccountEmail": "service@project.iam.gserviceaccount.com",
      "sheetId": "your-sheet-id",
      "worksheetName": "_moneyman"
    }
  },
  "options": {
    "scraping": {
      "daysBack": 10,
      "timezone": "Asia/Jerusalem"
    },
    "notifications": {
      "telegram": {
        "apiKey": "your-telegram-api-key",
        "chatId": "your-chat-id"
      }
    },
    "logging": {
      "debug": "moneyman:*",
      "separatedMode": true
    }
  }
}
EOF
```

**2. Run with Single Configuration Variable:**
```bash
# Docker (Recommended)
docker build -f Dockerfile.separated -t moneyman-separated .
export MONEYMAN_CONFIG="$(cat config.json)"
docker run -e MONEYMAN_CONFIG moneyman-separated

# Manual (for development/testing)
export MONEYMAN_CONFIG="$(cat config.json)"
npm run start:orchestrator  # Terminal 1  
npm run start:storage       # Terminal 2
npm run start:scraper       # Terminal 3

# One-liner for Docker
docker run -e MONEYMAN_CONFIG="$(cat config.json)" moneyman-separated
```

**3. Security Verification:**
```bash
# The container entry point automatically:
# 1. Parses and validates the JSON configuration with Zod
# 2. Distributes only relevant configuration to each service
# 3. Removes the original MONEYMAN_CONFIG from the environment
# 4. Each service validates it cannot access sensitive data from other services
```

## Security Benefits

1. **Credential Isolation**: Bank passwords only accessible to scraper process
2. **Dependency Isolation**: Complete separation of node_modules packages
   - Scraper: Only has bank scraping libraries, cannot access external service APIs
   - Storage: Only has external service libraries, cannot access bank scraping code
   - Orchestrator: Only has coordination libraries, cannot access sensitive operations
3. **Configuration Isolation**: Single JSON config parsed and distributed securely
   - Each service receives only its required configuration subset
   - Original MONEYMAN_CONFIG removed from environment after parsing
   - Services cannot access configuration from other services
4. **Zod Validation**: Early failing with comprehensive type-safe validation
   - Configuration errors caught before services start
   - Type safety ensures configuration integrity
   - Structured validation with clear error messages
5. **Minimal Attack Surface**: Each service has minimal dependencies and configuration
6. **Process Separation**: Different users prevent cross-contamination
7. **Network Controls**: Can restrict scraper from external APIs and vice versa
8. **Principle of Least Privilege**: Each service only has access to what it needs
9. **Shared Types Only**: Services share only TypeScript interfaces, no runtime code

## Configuration Security Model with MONEYMAN_CONFIG

A critical security feature of the separated architecture is **configuration isolation** using a single JSON configuration environment variable. The container entry point parses the configuration and distributes only the relevant sections to each service, with comprehensive validation using Zod.

### Configuration Distribution Architecture

```mermaid
graph TB
    subgraph "Container Runtime"
        MC[MONEYMAN_CONFIG<br/>JSON Configuration]
        
        subgraph "Entry Point Parser"
            EP[Entry Point Script]
            ZV[Zod Validation]
            CD[Configuration Distributor]
        end
        
        subgraph "Scraper Process (UID: 1001)"
            SC[Scraper Config:<br/>â€¢ accounts[]<br/>â€¢ scraping options<br/>â€¢ domain security<br/>â€¢ debugging]
        end
        
        subgraph "Storage Process (UID: 1002)"
            STC[Storage Config:<br/>â€¢ storage providers<br/>â€¢ API credentials<br/>â€¢ export settings<br/>â€¢ debugging]
        end
        
        subgraph "Orchestrator Process (UID: 1003)"
            OC[Orchestrator Config:<br/>â€¢ telegram settings<br/>â€¢ logging options<br/>â€¢ coordination settings<br/>â€¢ debugging]
        end
        
        MC --> EP
        EP --> ZV
        ZV --> CD
        CD -->|accounts + options.scraping| SC
        CD -->|storage + options.export| STC
        CD -->|notifications + options.logging| OC
    end
```

### MONEYMAN_CONFIG JSON Structure

The complete configuration is provided as a single JSON environment variable:

```json
{
  "accounts": [
    {
      "companyId": "hapoalim",
      "userCode": "AB1234", 
      "password": "p@ssword"
    },
    {
      "companyId": "visaCal",
      "username": "Ploni Almoni",
      "password": "p@ssword"
    }
  ],
  "storage": {
    "googleSheets": {
      "serviceAccountPrivateKey": "-----BEGIN PRIVATE KEY-----...",
      "serviceAccountEmail": "service@project.iam.gserviceaccount.com",
      "sheetId": "1ABC123...",
      "worksheetName": "_moneyman"
    },
    "ynab": {
      "token": "abc123...",
      "budgetId": "12345...",
      "accounts": {
        "5897": "ba2dd3a9-b7d4-46d6-8413-8327203e2b82"
      }
    },
    "azure": {
      "appId": "12345...",
      "appKey": "secret...",
      "tenantId": "tenant...",
      "databaseName": "moneyman",
      "tableName": "transactions",
      "ingestionMapping": "transaction_mapping",
      "ingestUri": "https://cluster.region.kusto.windows.net"
    },
    "buxfer": {
      "userName": "user@example.com",
      "password": "password123",
      "accounts": {
        "5897": "123456"
      }
    },
    "localJson": {
      "enabled": true
    },
    "webPost": {
      "url": "https://api.example.com/transactions",
      "authorizationToken": "Bearer token123"
    }
  },
  "options": {
    "scraping": {
      "accountsToScrape": ["hapoalim", "visaCal"],
      "daysBack": 10,
      "futureMonths": 1,
      "timezone": "Asia/Jerusalem",
      "transactionHashType": "moneyman",
      "additionalTransactionInfo": false,
      "hiddenDeprecations": ["some-deprecation"],
      "puppeteerExecutablePath": "/usr/bin/chromium",
      "maxParallelScrapers": 1,
      "domainTracking": true
    },
    "security": {
      "firewallSettings": "hapoalim ALLOW bankhapoalim.co.il\nvisaCal BLOCK suspicious-domain.com",
      "blockByDefault": false
    },
    "notifications": {
      "telegram": {
        "apiKey": "123456:ABC-DEF...",
        "chatId": "-123456789"
      }
    },
    "logging": {
      "debug": "moneyman:*",
      "separatedMode": true
    }
  }
}
```

### Configuration Distribution by Service

#### Scraper Service Configuration

**Receives Configuration Subset:**
```json
{
  "accounts": [
    { "companyId": "hapoalim", "userCode": "AB1234", "password": "p@ssword" }
  ],
  "options": {
    "scraping": {
      "accountsToScrape": ["hapoalim"],
      "daysBack": 10,
      "futureMonths": 1,
      "timezone": "Asia/Jerusalem",
      "transactionHashType": "moneyman",
      "additionalTransactionInfo": false,
      "hiddenDeprecations": ["some-deprecation"],
      "puppeteerExecutablePath": "/usr/bin/chromium",
      "maxParallelScrapers": 1,
      "domainTracking": true
    },
    "security": {
      "firewallSettings": "hapoalim ALLOW bankhapoalim.co.il",
      "blockByDefault": false
    },
    "logging": {
      "debug": "moneyman:*"
    }
  }
}
```

**Security Guarantees:**
- **NO access to storage credentials** (Google, YNAB, Azure, Buxfer)
- **NO access to notification credentials** (Telegram)
- **NO access to web export settings**
- **Cannot read original MONEYMAN_CONFIG** environment variable

#### Storage Service Configuration

**Receives Configuration Subset:**
```json
{
  "storage": {
    "googleSheets": {
      "serviceAccountPrivateKey": "-----BEGIN PRIVATE KEY-----...",
      "serviceAccountEmail": "service@project.iam.gserviceaccount.com",
      "sheetId": "1ABC123...",
      "worksheetName": "_moneyman"
    },
    "ynab": {
      "token": "abc123...",
      "budgetId": "12345...",
      "accounts": { "5897": "ba2dd3a9-b7d4-46d6-8413-8327203e2b82" }
    }
  },
  "options": {
    "logging": {
      "debug": "moneyman:*",
      "timezone": "Asia/Jerusalem"
    }
  }
}
```

**Security Guarantees:**
- **NO access to bank credentials** (accounts array)
- **NO access to scraping configuration**
- **NO access to notification credentials** (Telegram)
- **Cannot read original MONEYMAN_CONFIG** environment variable

#### Orchestrator Service Configuration

**Receives Configuration Subset:**
```json
{
  "options": {
    "notifications": {
      "telegram": {
        "apiKey": "123456:ABC-DEF...",
        "chatId": "-123456789"
      }
    },
    "logging": {
      "debug": "moneyman:*",
      "separatedMode": true,
      "timezone": "Asia/Jerusalem"
    }
  }
}
```

**Security Guarantees:**
- **NO access to bank credentials** (accounts array)
- **NO access to storage credentials** (Google, YNAB, Azure, Buxfer)
- **NO access to scraping configuration**
- **Cannot read original MONEYMAN_CONFIG** environment variable

### Zod Validation Schemas

The architecture uses **Zod 4** for comprehensive configuration validation with early failing to catch configuration errors before services start.

#### Complete Configuration Schema

```typescript
// shared-types/config-schema.ts
import { z } from 'zod';

// Account configuration schema
const AccountSchema = z.object({
  companyId: z.string().min(1, 'Company ID is required'),
  userCode: z.string().optional(),
  username: z.string().optional(), 
  password: z.string().min(1, 'Password is required'),
}).refine(
  (data) => data.userCode || data.username,
  { message: 'Either userCode or username is required' }
);

// Storage provider schemas
const GoogleSheetsSchema = z.object({
  serviceAccountPrivateKey: z.string().min(1, 'Google private key is required'),
  serviceAccountEmail: z.string().email('Invalid Google service account email'),
  sheetId: z.string().min(1, 'Google Sheet ID is required'),
  worksheetName: z.string().min(1, 'Worksheet name is required'),
});

const YnabSchema = z.object({
  token: z.string().min(1, 'YNAB token is required'),
  budgetId: z.string().min(1, 'YNAB budget ID is required'),
  accounts: z.record(z.string(), z.string()),
});

const AzureSchema = z.object({
  appId: z.string().min(1, 'Azure app ID is required'),
  appKey: z.string().min(1, 'Azure app key is required'),
  tenantId: z.string().min(1, 'Azure tenant ID is required'),
  databaseName: z.string().min(1, 'Database name is required'),
  tableName: z.string().min(1, 'Table name is required'),
  ingestionMapping: z.string().min(1, 'Ingestion mapping is required'),
  ingestUri: z.string().url('Invalid ingest URI'),
});

const BuxferSchema = z.object({
  userName: z.string().min(1, 'Buxfer username is required'),
  password: z.string().min(1, 'Buxfer password is required'),
  accounts: z.record(z.string(), z.string()),
});

const WebPostSchema = z.object({
  url: z.string().url('Invalid web post URL'),
  authorizationToken: z.string().min(1, 'Authorization token is required'),
});

// Storage configuration schema
const StorageSchema = z.object({
  googleSheets: GoogleSheetsSchema.optional(),
  ynab: YnabSchema.optional(),
  azure: AzureSchema.optional(),
  buxfer: BuxferSchema.optional(),
  localJson: z.object({ enabled: z.boolean() }).optional(),
  webPost: WebPostSchema.optional(),
}).refine(
  (data) => Object.values(data).some(Boolean),
  { message: 'At least one storage provider must be configured' }
);

// Options schemas
const ScrapingOptionsSchema = z.object({
  accountsToScrape: z.array(z.string()).optional(),
  daysBack: z.number().min(1).max(365).default(10),
  futureMonths: z.number().min(0).max(12).default(1),
  timezone: z.string().default('Asia/Jerusalem'),
  transactionHashType: z.enum(['', 'moneyman']).default(''),
  additionalTransactionInfo: z.boolean().default(false),
  hiddenDeprecations: z.array(z.string()).default([]),
  puppeteerExecutablePath: z.string().optional(),
  maxParallelScrapers: z.number().min(1).max(10).default(1),
  domainTracking: z.boolean().default(false),
});

const SecurityOptionsSchema = z.object({
  firewallSettings: z.string().optional(),
  blockByDefault: z.boolean().default(false),
});

const NotificationOptionsSchema = z.object({
  telegram: z.object({
    apiKey: z.string().min(1, 'Telegram API key is required'),
    chatId: z.string().min(1, 'Telegram chat ID is required'),
  }).optional(),
});

const LoggingOptionsSchema = z.object({
  debug: z.string().default(''),
  separatedMode: z.boolean().default(true),
  timezone: z.string().default('Asia/Jerusalem'),
});

// Complete configuration schema
export const MoneymanConfigSchema = z.object({
  accounts: z.array(AccountSchema).min(1, 'At least one account is required'),
  storage: StorageSchema,
  options: z.object({
    scraping: ScrapingOptionsSchema,
    security: SecurityOptionsSchema,
    notifications: NotificationOptionsSchema,
    logging: LoggingOptionsSchema,
  }),
});

export type MoneymanConfig = z.infer<typeof MoneymanConfigSchema>;
```

#### Service-Specific Configuration Schemas

```typescript
// Scraper service configuration schema
export const ScraperConfigSchema = z.object({
  accounts: z.array(AccountSchema),
  options: z.object({
    scraping: ScrapingOptionsSchema,
    security: SecurityOptionsSchema,
    logging: LoggingOptionsSchema.pick({ debug: true }),
  }),
});

export type ScraperConfig = z.infer<typeof ScraperConfigSchema>;

// Storage service configuration schema
export const StorageConfigSchema = z.object({
  storage: StorageSchema,
  options: z.object({
    logging: LoggingOptionsSchema.pick({ debug: true, timezone: true }),
  }),
});

export type StorageConfig = z.infer<typeof StorageConfigSchema>;

// Orchestrator service configuration schema
export const OrchestratorConfigSchema = z.object({
  options: z.object({
    notifications: NotificationOptionsSchema,
    logging: LoggingOptionsSchema,
  }),
});

export type OrchestratorConfig = z.infer<typeof OrchestratorConfigSchema>;
```

### Implementation Strategy

#### Docker Entrypoint Script with Configuration Parsing

```bash
#!/bin/bash
# docker-entrypoint-separated.sh

set -e

# Validate MONEYMAN_CONFIG is provided
if [[ -z "${MONEYMAN_CONFIG}" ]]; then
    echo "ERROR: MONEYMAN_CONFIG environment variable is required"
    exit 1
fi

# Create configuration parser using Node.js
cat > /tmp/config-parser.js << 'EOF'
const fs = require('fs');

// Parse and validate MONEYMAN_CONFIG
let config;
try {
    config = JSON.parse(process.env.MONEYMAN_CONFIG);
} catch (error) {
    console.error('ERROR: Invalid JSON in MONEYMAN_CONFIG:', error.message);
    process.exit(1);
}

// Extract service-specific configurations
const scraperConfig = {
    accounts: config.accounts,
    options: {
        scraping: config.options.scraping,
        security: config.options.security,
        logging: { debug: config.options.logging.debug }
    }
};

const storageConfig = {
    storage: config.storage,
    options: {
        logging: {
            debug: config.options.logging.debug,
            timezone: config.options.logging.timezone
        }
    }
};

const orchestratorConfig = {
    options: {
        notifications: config.options.notifications,
        logging: config.options.logging
    }
};

// Write service configurations to files
fs.writeFileSync('/tmp/scraper-config.json', JSON.stringify(scraperConfig, null, 2));
fs.writeFileSync('/tmp/storage-config.json', JSON.stringify(storageConfig, null, 2));
fs.writeFileSync('/tmp/orchestrator-config.json', JSON.stringify(orchestratorConfig, null, 2));

console.log('Configuration parsed and distributed successfully');
EOF

# Parse configuration
node /tmp/config-parser.js

# Verify configuration files were created
if [[ ! -f "/tmp/scraper-config.json" || ! -f "/tmp/storage-config.json" || ! -f "/tmp/orchestrator-config.json" ]]; then
    echo "ERROR: Failed to create configuration files"
    exit 1
fi

# Set secure permissions on configuration files
chmod 600 /tmp/scraper-config.json
chmod 600 /tmp/storage-config.json
chmod 600 /tmp/orchestrator-config.json

# Change ownership of configuration files
chown scraper:scraper /tmp/scraper-config.json
chown storage:storage /tmp/storage-config.json
chown orchestrator:orchestrator /tmp/orchestrator-config.json

# Clear the original MONEYMAN_CONFIG from environment
unset MONEYMAN_CONFIG

# Start services with their specific configurations
echo "Starting orchestrator service..."
su orchestrator -c "cd /app/orchestrator-service && MONEYMAN_SERVICE_CONFIG=/tmp/orchestrator-config.json node index.js" &

echo "Starting storage service..."  
su storage -c "cd /app/storage-service && MONEYMAN_SERVICE_CONFIG=/tmp/storage-config.json node index.js" &

echo "Starting scraper service..."
su scraper -c "cd /app/scraper-service && MONEYMAN_SERVICE_CONFIG=/tmp/scraper-config.json node index.js" &

# Wait for all services
wait
```

#### Configuration Loading in Services

Each service loads its configuration subset using a secure configuration loader:

```typescript
// shared-types/config-loader.ts
import { readFileSync } from 'fs';
import { ScraperConfigSchema, StorageConfigSchema, OrchestratorConfigSchema } from './config-schema.js';

export function loadScraperConfig(): ScraperConfig {
    const configPath = process.env.MONEYMAN_SERVICE_CONFIG;
    if (!configPath) {
        throw new Error('MONEYMAN_SERVICE_CONFIG environment variable is required');
    }
    
    // Verify original MONEYMAN_CONFIG is not accessible
    if (process.env.MONEYMAN_CONFIG) {
        throw new Error('Security violation: Original MONEYMAN_CONFIG should not be accessible');
    }
    
    try {
        const configText = readFileSync(configPath, 'utf-8');
        const config = JSON.parse(configText);
        
        // Validate configuration with Zod
        return ScraperConfigSchema.parse(config);
    } catch (error) {
        throw new Error(`Failed to load scraper configuration: ${error.message}`);
    }
}

export function loadStorageConfig(): StorageConfig {
    const configPath = process.env.MONEYMAN_SERVICE_CONFIG;
    if (!configPath) {
        throw new Error('MONEYMAN_SERVICE_CONFIG environment variable is required');
    }
    
    // Verify original MONEYMAN_CONFIG is not accessible
    if (process.env.MONEYMAN_CONFIG) {
        throw new Error('Security violation: Original MONEYMAN_CONFIG should not be accessible');
    }
    
    try {
        const configText = readFileSync(configPath, 'utf-8');
        const config = JSON.parse(configText);
        
        // Validate configuration with Zod
        return StorageConfigSchema.parse(config);
    } catch (error) {
        throw new Error(`Failed to load storage configuration: ${error.message}`);
    }
}

export function loadOrchestratorConfig(): OrchestratorConfig {
    const configPath = process.env.MONEYMAN_SERVICE_CONFIG;
    if (!configPath) {
        throw new Error('MONEYMAN_SERVICE_CONFIG environment variable is required');
    }
    
    // Verify original MONEYMAN_CONFIG is not accessible
    if (process.env.MONEYMAN_CONFIG) {
        throw new Error('Security violation: Original MONEYMAN_CONFIG should not be accessible');
    }
    
    try {
        const configText = readFileSync(configPath, 'utf-8');
        const config = JSON.parse(configText);
        
        // Validate configuration with Zod
        return OrchestratorConfigSchema.parse(config);
    } catch (error) {
        throw new Error(`Failed to load orchestrator configuration: ${error.message}`);
    }
}
```

### Security Validation

#### Configuration Access Auditing

```typescript
// shared-types/config-audit.ts
export interface ConfigurationAudit {
  service: 'scraper' | 'storage' | 'orchestrator';
  configurationReceived: string[];
  sensitiveDataBlocked: string[];
  violations: string[];
}

export function auditConfigurationAccess(
  service: 'scraper' | 'storage' | 'orchestrator',
  config: any
): ConfigurationAudit {
  const violations: string[] = [];
  
  // Check for MONEYMAN_CONFIG environment variable access
  if (process.env.MONEYMAN_CONFIG) {
    violations.push('Security violation: Original MONEYMAN_CONFIG is accessible');
  }
  
  // Service-specific auditing
  switch (service) {
    case 'scraper':
      return auditScraperConfig(config, violations);
    case 'storage':
      return auditStorageConfig(config, violations);
    case 'orchestrator':
      return auditOrchestratorConfig(config, violations);
  }
}

function auditScraperConfig(config: any, violations: string[]): ConfigurationAudit {
  const received: string[] = [];
  const blocked: string[] = [];
  
  // Check what configuration is received
  if (config.accounts) received.push('accounts');
  if (config.options?.scraping) received.push('scraping options');
  if (config.options?.security) received.push('security options');
  
  // Check for blocked sensitive data
  if (config.storage) {
    violations.push('Scraper has access to storage credentials');
    blocked.push('storage credentials');
  }
  if (config.options?.notifications) {
    violations.push('Scraper has access to notification credentials');
    blocked.push('notification credentials');
  }
  
  return {
    service: 'scraper',
    configurationReceived: received,
    sensitiveDataBlocked: blocked,
    violations
  };
}

function auditStorageConfig(config: any, violations: string[]): ConfigurationAudit {
  const received: string[] = [];
  const blocked: string[] = [];
  
  // Check what configuration is received
  if (config.storage) received.push('storage providers');
  if (config.options?.logging) received.push('logging options');
  
  // Check for blocked sensitive data
  if (config.accounts) {
    violations.push('Storage service has access to bank credentials');
    blocked.push('bank credentials');
  }
  if (config.options?.scraping) {
    violations.push('Storage service has access to scraping configuration');
    blocked.push('scraping configuration');
  }
  if (config.options?.notifications) {
    violations.push('Storage service has access to notification credentials');
    blocked.push('notification credentials');
  }
  
  return {
    service: 'storage',
    configurationReceived: received,
    sensitiveDataBlocked: blocked,
    violations
  };
}

function auditOrchestratorConfig(config: any, violations: string[]): ConfigurationAudit {
  const received: string[] = [];
  const blocked: string[] = [];
  
  // Check what configuration is received
  if (config.options?.notifications) received.push('notification settings');
  if (config.options?.logging) received.push('logging settings');
  
  // Check for blocked sensitive data
  if (config.accounts) {
    violations.push('Orchestrator has access to bank credentials');
    blocked.push('bank credentials');
  }
  if (config.storage) {
    violations.push('Orchestrator has access to storage credentials');
    blocked.push('storage credentials');
  }
  if (config.options?.scraping) {
    violations.push('Orchestrator has access to scraping configuration');
    blocked.push('scraping configuration');
  }
  
  return {
    service: 'orchestrator',
    configurationReceived: received,
    sensitiveDataBlocked: blocked,
    violations
  };
}
```

#### Runtime Security Checks

```typescript
// shared-types/security-checks.ts
export class SecurityValidator {
  static validateEnvironment(service: 'scraper' | 'storage' | 'orchestrator'): void {
    // Ensure original configuration is not accessible
    if (process.env.MONEYMAN_CONFIG) {
      throw new Error(`Security violation: ${service} service has access to MONEYMAN_CONFIG`);
    }
    
    // Ensure service config is properly isolated
    if (!process.env.MONEYMAN_SERVICE_CONFIG) {
      throw new Error(`Security violation: ${service} service missing MONEYMAN_SERVICE_CONFIG`);
    }
    
    // Additional service-specific checks
    switch (service) {
      case 'scraper':
        this.validateScraperEnvironment();
        break;
      case 'storage':
        this.validateStorageEnvironment();
        break;
      case 'orchestrator':
        this.validateOrchestratorEnvironment();
        break;
    }
  }
  
  private static validateScraperEnvironment(): void {
    // Ensure no external service environment variables are present
    const blockedVars = [
      'GOOGLE_SERVICE_ACCOUNT_PRIVATE_KEY',
      'YNAB_TOKEN', 
      'AZURE_APP_KEY',
      'TELEGRAM_API_KEY'
    ];
    
    for (const varName of blockedVars) {
      if (process.env[varName]) {
        throw new Error(`Security violation: Scraper has access to ${varName}`);
      }
    }
  }
  
  private static validateStorageEnvironment(): void {
    // Ensure no bank credentials are present
    const blockedVars = ['ACCOUNTS_JSON', 'BANK_PASSWORD'];
    
    for (const varName of blockedVars) {
      if (process.env[varName]) {
        throw new Error(`Security violation: Storage service has access to ${varName}`);
      }
    }
  }
  
  private static validateOrchestratorEnvironment(): void {
    // Ensure no sensitive credentials are present
    const blockedVars = [
      'ACCOUNTS_JSON',
      'GOOGLE_SERVICE_ACCOUNT_PRIVATE_KEY', 
      'YNAB_TOKEN',
      'AZURE_APP_KEY'
    ];
    
    for (const varName of blockedVars) {
      if (process.env[varName]) {
        throw new Error(`Security violation: Orchestrator has access to ${varName}`);
      }
    }
  }
}
```

## Backward Compatibility

- **Unified mode remains default behavior**: Existing users continue using original approach
- **All existing functionality preserved**: No breaking changes to current features
- **Environment variable support**: Original individual environment variables still work in unified mode
- **Gradual migration**: Users can migrate to MONEYMAN_CONFIG when ready
- **Same Docker image**: Can run both modes with different entry points
- **Configuration conversion**: Tool provided to convert from individual env vars to MONEYMAN_CONFIG

### Migration Path

**1. Current users (individual environment variables):**
```bash
# Continues to work as before
docker run -e ACCOUNTS_JSON='[...]' -e GOOGLE_SHEET_ID='...' moneyman
```

**2. New users (MONEYMAN_CONFIG):**
```bash
# Enhanced security with single configuration
docker run -e MONEYMAN_CONFIG='{"accounts":[...],"storage":{...}}' moneyman-separated
```

**3. Migration tool:**
```bash
# Convert existing environment variables to MONEYMAN_CONFIG format
npm run convert-config
```

## Testing Strategy

1. **Unified mode compatibility**: All existing tests must pass in unified mode
2. **Configuration validation**: Test Zod schemas with valid and invalid configurations
3. **Configuration distribution**: Verify each service receives only its subset
4. **Security isolation**: Test that services cannot access sensitive configuration from other services
5. **ZeroMQ communication**: Add tests for inter-service message passing
6. **Integration tests**: Test separated mode end-to-end functionality
7. **Error handling**: Test configuration parsing errors and service boundary errors
8. **Environment security**: Verify MONEYMAN_CONFIG is properly removed from service environments
9. **Service startup validation**: Test that services fail fast with invalid configurations
10. **Migration testing**: Test conversion from individual env vars to MONEYMAN_CONFIG

## Dependencies

### Root Package Dependencies (Development Only)
- `typescript`: For building both services
- `jest`: For testing
- `@types/*`: TypeScript definitions
- `concurrently`: For running services in development

### Shared Dependencies (All Services)
- `zod@^4.0.0`: Configuration validation and type safety
  - Used for validating MONEYMAN_CONFIG JSON structure
  - Provides early failing with comprehensive error messages
  - Ensures type safety across configuration distribution

### Service-Specific Dependencies

#### Scraper Service Only
- `israeli-bank-scrapers`: Bank scraping functionality
- `puppeteer`: Browser automation
- `zeromq`: Inter-service communication
- `zod`: Configuration validation

#### Storage Service Only  
- `googleapis`: Google Sheets integration
- `ynab`: YNAB API integration
- `@azure/storage-blob`: Azure blob storage
- `zeromq`: Inter-service communication
- `zod`: Configuration validation

#### Orchestrator Service Only
- `node-telegram-bot-api`: Telegram notifications
- `winston`: Logging
- `zeromq`: Inter-service communication
- `zod`: Configuration validation

### Implementation Requirements

When implementing this architecture, the following dependencies must be added:

```bash
# Add Zod 4 to main package.json
npm install zod@^4.0.0

# Add Zod 4 to each service package.json as well
cd scraper-service && npm install zod@^4.0.0
cd ../storage-service && npm install zod@^4.0.0  
cd ../orchestrator-service && npm install zod@^4.0.0
```

### Dependency Isolation Benefits

1. **Reduced Attack Surface**: Each service only has dependencies it actually uses
2. **Faster Installation**: Smaller dependency trees per service
3. **Better Security Auditing**: Can audit each service's dependencies separately
4. **Easier Maintenance**: Update external API libraries without affecting scraper
5. **Compliance**: Clear separation for security audits and compliance requirements
6. **Configuration Type Safety**: Zod validation ensures configuration integrity across all services
7. **Early Error Detection**: Configuration errors caught before any service starts

### Package.json Scripts
- `start:scraper`: Start scraper service
- `start:storage`: Start storage service
- `start:orchestrator`: Start orchestrator service
- `start:separated`: Start all services in separated mode (development)

## Rollout Plan

1. Implement separated architecture with backward compatibility
2. Test thoroughly in both modes
3. Deploy with separated mode disabled by default
4. Gradually enable separated mode for security-conscious users
5. Consider making separated mode default in future major version

## Docker Implementation with User Separation

### Dockerfile Example with User Separation

```dockerfile
# Dockerfile.separated
FROM node:18-alpine AS base

# Create users with specific UIDs
RUN addgroup -g 1001 scraper && adduser -D -u 1001 -G scraper scraper
RUN addgroup -g 1002 storage && adduser -D -u 1002 -G storage storage

# Install dependencies
WORKDIR /app
COPY package*.json ./
RUN npm ci --production

# Copy source code
COPY . .

# Build TypeScript
RUN npm run build

# Create directories with proper permissions
RUN mkdir -p /app/scraper-service /app/storage-service
RUN chown scraper:scraper /app/scraper-service
RUN chown storage:storage /app/storage-service

# Scraper service stage
FROM base AS scraper
USER scraper
WORKDIR /app
EXPOSE 5555
CMD ["node", "scraper-service/index.js"]

# Storage service stage  
FROM base AS storage
USER storage
WORKDIR /app
CMD ["node", "storage-service/index.js"]

# Combined stage for separated mode
FROM base AS separated
COPY docker-entrypoint-separated.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh
ENTRYPOINT ["/entrypoint.sh"]
```

### Network Security with iptables

#### Container Network Isolation Script

```bash
#!/bin/bash
# setup-container-security.sh

# Get container PID and network namespace
CONTAINER_PID=$(docker inspect --format '{{.State.Pid}}' moneyman-separated-container)

# Enter container network namespace and apply rules
nsenter -t $CONTAINER_PID -n iptables -A OUTPUT -m owner --uid-owner 1001 -j SCRAPER_RULES
nsenter -t $CONTAINER_PID -n iptables -N SCRAPER_RULES

# Allow scraper to access only banking domains
BANK_DOMAINS=(
    "otsar-hahayal.co.il"
    "bankhapoalim.co.il" 
    "mizrahi-tefahot.co.il"
    "bankleumi.co.il"
    "bankyahav.co.il"
    "discount.co.il"
    "fibi.co.il"
    "unionbank.co.il"
)

for domain in "${BANK_DOMAINS[@]}"; do
    # Resolve domain to IP (simplified - in production use DNS monitoring)
    IPS=$(dig +short "$domain" | grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$')
    for ip in $IPS; do
        nsenter -t $CONTAINER_PID -n iptables -A SCRAPER_RULES -d "$ip" -j ACCEPT
    done
done

# Allow localhost for IPC communication
nsenter -t $CONTAINER_PID -n iptables -A SCRAPER_RULES -d 127.0.0.1 -j ACCEPT

# Block all other outbound traffic for scraper (allow-list approach)
nsenter -t $CONTAINER_PID -n iptables -A SCRAPER_RULES -j DROP

# Enter storage container network namespace and apply rules  
nsenter -t $CONTAINER_PID -n iptables -A OUTPUT -m owner --uid-owner 1002 -j STORAGE_RULES
nsenter -t $CONTAINER_PID -n iptables -N STORAGE_RULES

# Allow storage to access external service domains
EXTERNAL_DOMAINS=(
    "sheets.googleapis.com"
    "api.youneedabudget.com" 
    "api.telegram.org"
    "management.azure.com"
    "*.blob.core.windows.net"
)

for domain in "${EXTERNAL_DOMAINS[@]}"; do
    # Handle wildcards and resolve IPs
    if [[ "$domain" == *"*"* ]]; then
        # For wildcards, allow the parent domain range (simplified)
        parent_domain="${domain#*.}"
        IPS=$(dig +short "$parent_domain" | grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$')
    else
        IPS=$(dig +short "$domain" | grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$')
    fi
    
    for ip in $IPS; do
        nsenter -t $CONTAINER_PID -n iptables -A STORAGE_RULES -d "$ip" -j ACCEPT
    done
done

# Allow localhost for IPC communication
nsenter -t $CONTAINER_PID -n iptables -A STORAGE_RULES -d 127.0.0.1 -j ACCEPT

# Default deny for storage (allow-list approach) 
nsenter -t $CONTAINER_PID -n iptables -A STORAGE_RULES -j DROP

# Configure orchestrator service rules
nsenter -t $CONTAINER_PID -n iptables -A OUTPUT -m owner --uid-owner 1003 -j ORCHESTRATOR_RULES
nsenter -t $CONTAINER_PID -n iptables -N ORCHESTRATOR_RULES

# Allow orchestrator to access Telegram API only
nsenter -t $CONTAINER_PID -n iptables -A ORCHESTRATOR_RULES -d $(dig +short api.telegram.org) -j ACCEPT

# Allow localhost for IPC communication
nsenter -t $CONTAINER_PID -n iptables -A ORCHESTRATOR_RULES -d 127.0.0.1 -j ACCEPT

# Default deny for orchestrator
nsenter -t $CONTAINER_PID -n iptables -A ORCHESTRATOR_RULES -j DROP

echo "Network security rules applied successfully"
```

#### Domain Whitelist Configuration

```yaml
# security-config.yml
network_security:
  scraper_allowed_domains:
    # Israeli Banks
    - "otsar-hahayal.co.il"
    - "bankhapoalim.co.il"
    - "mizrahi-tefahot.co.il" 
    - "bankleumi.co.il"
    - "bankyahav.co.il"
    - "discount.co.il"
    - "fibi.co.il"
    - "unionbank.co.il"
    # Credit Cards
    - "cal-online.co.il"
    - "max.co.il"
    - "isracard.co.il"
    # Infrastructure
    - "127.0.0.1"  # IPC communication
    
  storage_allowed_domains:
    # External Services  
    - "sheets.googleapis.com"
    - "www.googleapis.com"
    - "api.youneedabudget.com"
    - "api.telegram.org"
    - "management.azure.com"
    - "*.blob.core.windows.net"
    - "login.microsoftonline.com"
    # Infrastructure  
    - "127.0.0.1"  # IPC communication
```

## Build and Test Scripts for Separated Mode

### Build Scripts

#### Master Build Script
```bash
#!/bin/bash
# scripts/build.sh

set -e

echo "ðŸ—ï¸  Building MoneyMan with separated architecture..."

# Build TypeScript
echo "Compiling TypeScript..."
npm run build

# Build unified Docker image (backward compatibility)
echo "Building unified Docker image..."
docker build -t moneyman:latest .

# Build separated Docker image (single container)
echo "Building separated Docker image..."
docker build -f Dockerfile.separated -t moneyman:separated .

echo "âœ… Build completed successfully!"
```

#### Development Build Script  
```bash
#!/bin/bash
# scripts/build-dev.sh

set -e

echo "ðŸ”§ Building for development..."

# Install dependencies
npm install

# Build TypeScript with watch mode in background
echo "Starting TypeScript compilation in watch mode..."
npm run build:watch &
BUILD_PID=$!

# Function to cleanup on exit
cleanup() {
    echo "Stopping build process..."
    kill $BUILD_PID 2>/dev/null || true
}
trap cleanup EXIT

echo "âœ… Development build started. Press Ctrl+C to stop."
wait $BUILD_PID
```

### Test Scripts

#### Comprehensive Test Script
```bash
#!/bin/bash
# scripts/test.sh

set -e

TEST_MODE=${1:-"all"}

echo "ðŸ§ª Running MoneyMan tests..."

run_unit_tests() {
    echo "Running unit tests..."
    npm test
}

run_integration_tests() {
    echo "Running integration tests..."
    npm run test:integration
}

run_separated_mode_tests() {
    echo "ðŸ”€ Testing separated mode..."
    
    # Start ZeroMQ in test mode
    echo "Starting test ZeroMQ broker..."
    docker run -d --name zeromq-test -p 5556:5555 redis:alpine redis-server --port 5555 &
    ZEROMQ_PID=$!
    
    # Test scraper service in isolation
    echo "Testing scraper service..."
    SEPARATED_MODE=true STORAGE_ENDPOINT=tcp://127.0.0.1:5556 npm run test:scraper
    
    # Test storage service in isolation  
    echo "Testing storage service..."
    SEPARATED_MODE=true STORAGE_ENDPOINT=tcp://127.0.0.1:5556 npm run test:storage
    
    # Test end-to-end communication
    echo "Testing service communication..."
    npm run test:e2e:separated
    
    # Cleanup
    docker stop zeromq-test 2>/dev/null || true
    docker rm zeromq-test 2>/dev/null || true
}

run_security_tests() {
    echo "ðŸ”’ Running security tests..."
    
    # Test user separation
    echo "Testing Docker user separation..."
    docker run --rm moneyman:separated id  # Will show different users for different processes
    
    # Test network isolation (requires privileged mode)
    if [[ "$EUID" -eq 0 ]]; then
        echo "Testing network isolation..."
        ./scripts/test-network-isolation.sh
    else
        echo "âš ï¸  Skipping network isolation tests (requires root)"
    fi
    
    # Test credential isolation
    echo "Testing credential isolation..."
    npm run test:security:credentials
}

run_docker_tests() {
    echo "ðŸ³ Testing Docker configurations..."
    
    # Test unified mode
    echo "Testing unified Docker mode..."
    docker run --rm -e NODE_ENV=test moneyman:latest npm test
    
    # Test separated mode
    echo "Testing separated Docker mode..."
    docker-compose -f docker-compose.test.yml up --abort-on-container-exit
    docker-compose -f docker-compose.test.yml down
}

# Main execution
case $TEST_MODE in
    "unit")
        run_unit_tests
        ;;
    "integration")  
        run_integration_tests
        ;;
    "separated")
        run_separated_mode_tests
        ;;
    "security")
        run_security_tests
        ;;
    "docker")
        run_docker_tests
        ;;
    "all")
        run_unit_tests
        run_integration_tests
        run_separated_mode_tests
        run_security_tests
        run_docker_tests
        ;;
    *)
        echo "Usage: $0 [unit|integration|separated|security|docker|all]"
        exit 1
        ;;
esac

echo "âœ… All tests completed successfully!"
```

#### Quick Development Test Script
```bash
#!/bin/bash  
# scripts/test-dev.sh

set -e

echo "ðŸš€ Quick development tests..."

# Run linting
echo "Linting code..."
npm run lint

# Run unit tests only
echo "Running unit tests..."
npm run test:unit

# Test TypeScript compilation
echo "Testing TypeScript compilation..."
npm run build

# Test separated mode locally (without Docker)
echo "Testing separated mode locally..."
SEPARATED_MODE=true npm run test:local:separated

echo "âœ… Development tests passed!"
```

### Docker Compose for Easy Testing

```yaml
# docker-compose.test.yml  
version: '3.8'

services:
  moneyman-separated-test:
    build:
      context: .
      dockerfile: Dockerfile.separated
    environment:
      - NODE_ENV=test
      - SEPARATED_MODE=true
    volumes:
      - ./test-data:/app/test-data:ro
      - /tmp/moneyman-ipc:/tmp/moneyman-ipc
    privileged: true  # Required for process management and user switching
    networks:
      - test-network
      
networks:
  test-network:
    driver: bridge
```

### Package.json Scripts Addition

```json
{
  "scripts": {
    "build": "tsc",
    "build:watch": "tsc --watch",
    "build:docker": "./scripts/build.sh",
    "build:dev": "./scripts/build-dev.sh",
    
    "test": "jest",
    "test:unit": "jest --testPathPattern=unit",
    "test:integration": "jest --testPathPattern=integration", 
    "test:scraper": "jest --testPathPattern=scraper",
    "test:storage": "jest --testPathPattern=storage",
    "test:e2e:separated": "jest --testPathPattern=e2e/separated",
    "test:security:credentials": "jest --testPathPattern=security/credentials",
    "test:local:separated": "concurrently \"npm run start:storage\" \"npm run start:scraper\"",
    "test:dev": "./scripts/test-dev.sh",
    "test:all": "./scripts/test.sh all",
    "test:separated": "./scripts/test.sh separated",
    "test:security": "./scripts/test.sh security",
    
    "start:scraper": "node scraper-service/index.js",
    "start:storage": "node storage-service/index.js",
    "start:orchestrator": "node orchestrator-service/index.js", 
    "start:separated": "concurrently \"npm run start:orchestrator\" \"npm run start:storage\" \"npm run start:scraper\"",
    "start:dev:separated": "concurrently \"npm run start:orchestrator\" \"npm run start:storage\" \"npm run start:scraper\" --kill-others-on-fail"
  }
}
```

## Future Enhancements

1. **Container Orchestration**: Use Docker Compose for easier separated deployment
2. **Health Checks**: Add health monitoring for both services
3. **Metrics**: Add monitoring and metrics collection
4. **Configuration Management**: Centralized configuration service
5. **High Availability**: Multiple scraper instances with load balancing